---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ## About ## -->
__About.__ I'm an AI researcher at Microsoft Research in the [Deep Reinforcement Learning for Games](https://www.microsoft.com/en-us/research/group/deep-reinforcement-learning/) team. I have wide-ranging interest across AI and machine learning, with expertise in uncertainty estimation in neural networks, and imitation learning.

<!-- having worked on  uncertainty estimation in neural networks, Bayesian deep learning, survival analysis, behavioural cloning for video games, the exploration/exploitation dilemma, and algorithmic music composition. -->



<!-- In general my research follows two philosophies; 1) Analysing and designing neural networks from a probabilistic view o -->

<!-- and am particularly drawn to the probabilistic view of learning with neural networks, and building RL agents. -->

__Previous.__ I completed my PhD at the [University of Cambridge](https://www.ifm.eng.cam.ac.uk/research/manufacturing-analytics/), spending time at the [Alan Turing Institute](https://www.turing.ac.uk/), and then did a postdoc at [Tsinghua University](https://ml.cs.tsinghua.edu.cn/). In my previous life I qualified as a Chartered Accountant with Ernst & Young (EY), building forecasting and valuation models for clients across London finance. I also spent one year in Taiwan studying 中文.

__Research Philosophy.__ 1) I adopt a probabilistic view of neural networks to help understand today's algorithms and design those of tomorrow. 2) I believe that RL, with it's mix of sequential decisions and interactive learning, is the correct setting to be studying to make long-term progress in AI.

__Get in Touch.__ If you'd like to chat about research, collaborating together, or other opportunities, reach me via email at $x$@microsoft.com, where, $x=\text{tim.pearce}$. I'm more active on Twitter than here, so for up-to-date news, [follow me](https://twitter.com/Tea_Pearce).

<!-- where my research explored how to get better uncertainty estimates from deep neural networks. I continued to explore this in my Postdoc at [Tsinghua University](https://ml.cs.tsinghua.edu.cn/), where I also began building behavioural  -->

<!-- In particular focusing on ensembling methods, and priors in Bayesian neural networks.  -->

<!-- I'm a 4th year engineering PhD at the University of Cambridge, having spent time at the [Alan Turing Institute](https://en.wikipedia.org/wiki/Alan_Turing_Institute).  -->

<!-- I completed an internship in reinforcement learning at [PROWLER.io/Secondmind](https://www.secondmind.ai/) and in causal ML at [FDL](https://frontierdevelopmentlab.org/) (NASA research accelerator). -->



## Selected Publications ## 

See my [Google Scholar](https://scholar.google.co.uk/citations?hl=en&user=09k1kdQAAAAJ&view_op=list_works&sortby=pubdate) for a comprehensive list.  

__T Pearce__, T Rashid, A Kanervisto, D Bignell, M Sun, R Georgescu, SV Macua, SZ Tan, I Momennejad, K Hofmann, S Devlin  
Imitating Human Behaviour with Diffusion Models  
__ICLR, 2023__  
[Paper](https://arxiv.org/abs/2301.10677)

__T Pearce__, JH Jeong, Y Jia, J Zhu  
Censored Quantile Regression Neural Networks  
__NeurIPS 2022__  
[Paper](https://arxiv.org/abs/2205.13496)  | [Code](https://github.com/TeaPearce/Censored_Quantile_Regression_NN)

F Lin*, S Huang*, __T Pearce__, W Chen, W-W Tu  
TiZero: Mastering Multi-Agent Football with Curriculum Learning and Self-Play  
__AAMAS 2023__

__T Pearce__, J Zhu  
Counter-Strike Deathmatch with Large-Scale Behavioural Cloning  
__IEEE Conference on Games 2022, Best Paper Award__  
[Paper](https://arxiv.org/abs/2104.04258) | [Video Intro](https://youtu.be/rnz3lmfSHv0) | [Code](https://github.com/TeaPearce/Counter-Strike_Behavioural_Cloning)

__T Pearce__, A Brintrup, J Zhu  
Understanding Softmax Confidence and Uncertainty   
__ArXiv 2021__  
[Paper](https://arxiv.org/abs/1810.05546) 

R Tsuchida, __T Pearce__, C Van Der Heide, F Roosta, M Gallagher  
Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks  
__AAAI 2021__  
[Paper](https://arxiv.org/abs/2002.08517)  

__T Pearce__, Andrew Y. K. Foong, Alexandra Brintrup  
Structured Priors for Convolutional Neural Networks  
__ICML workshop, Uncertainty & Robustness in Deep Learning 2020__  
[Paper](https://arxiv.org/abs/2007.14235)  | [Code](https://github.com/TeaPearce/Struct_Weight_Priors_CNNs)

__T Pearce__, F Leibfried, M Zaki, A Brintrup, A Neely  
Uncertainty in Neural Networks: Approximately Bayesian Ensembling  
__AISTATS 2021__  
[Paper](https://arxiv.org/abs/1810.05546) | [Video Intro](https://youtu.be/eBKqvgecRjc) | [Interactive Demo](https://teapearce.github.io/portfolio/)  | [Code](https://github.com/TeaPearce/Bayesian_NN_Ensembles)

__T Pearce__, R Tsuchida, M Zaki, A Brintrup, A Neely  
Expressive Priors in Bayesian Neural Networks: Kernel Combinations and Periodic Functions  
__UAI 2019__  
[Paper](https://arxiv.org/abs/1905.06076) | [Video Intro](https://youtu.be/D5pfY12BuyA)  | [Code](https://github.com/TeaPearce/Expressive_Priors_in_BNNs)

__T Pearce__, M Zaki, A Brintrup, A Neely  
High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach   
__ICML 2018__  
[Paper](https://arxiv.org/abs/1802.07167) | [Video Intro](https://crossminds.ai/video/high-quality-prediction-intervals-for-deep-learning-a-distribution-free-ensembled-approach-6064c11294c854625bdac99b/)  | [Code](https://github.com/TeaPearce/Deep_Learning_Prediction_Intervals)


## Videos ##

I sometimes make short videos summarising research papers I find interesting.

* [A robotic system that plays table tennis with RL](https://youtu.be/ktkbxWcYiF8)  
* [AlphaCode explained](https://youtu.be/YjsoN5aJChA)  


## Teaching ##

I did the below teaching on courses at the University of Cambridge. 

Lecturer  
* 2019-21 	- Intro to Deep Learning, 		      	MPhil engineering Data and Modelling
*	2019-20 	- Intro to Deep Learning, 		      	4th yr engineering Industrial Operations Mgmt

Tutor – Teaching groups of 3-5 students (Oxbridge speak: ‘supervisions’)  
*	2018-20 	- Foundations of Data Science, 	      	2nd yr undergrad Computer Science
*	2018-20 	- Artificial Intelligence, 		      	2nd yr undergrad Computer Science
*	2018-19 	- Foundations of Computer Science,   	1st yr undergrad Computer Science
*	2017-19	- Quantitative Methods, 			Management MPhil
*	2019-20 	- Statistical Signal Processing, 	       	3rd yr Information Engineering

Lab Demonstrator  
*	2017-18 	- Intro to machine & assembly code, 	1st yr engineering
*	2018-19 	- Intro to robotics,				1st yr engineering

<!-- ## Supervising ## -->
<!-- Master’s Thesis -->
<!-- *	2018-19, David Ratiney, Uncertainty in Neural Networks: Application to supply chain forecasting -->

## News ##

- Jan 2023. 1x ICLR paper accepted.
- Jan 2023. Giving a talk at Tsinghua TSAIL group on diffusion models for imitation learning.
- Dec 2022. Will be attending NeurIPS.
- July 2022. My paper on behavioural cloning for counter-strike won best paper at IEEE CoG.
- May 2022. I will be joining Microsoft Research as an AI researcher.


